from flask import Flask, render_template, request, jsonify
import os
import leventest
from dotenv import load_dotenv
from openai import OpenAI

app = Flask(__name__)
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    user_input = request.form['user_input']
    if user_input.lower() == 'exit':
        return jsonify({'response': 'Goodbye!'})
    else:
        answer = get_answer_from_chatbot(user_input)
        return jsonify({'response': answer})

def get_answer_from_chatbot(user_input):
    # Implement your chatbot logic here
    # For example, you can use OpenAI's API to generate a response
    answer = leventest.get_answer(user_input, leventest.database)
    if answer:
        return answer
    else:
        background_info = "" #this can be used to provide context to the chatbot
        prompt = f"{background_info}\nUser: {user_input}"
        completion = client.chat.completions.create(
            messages=[
                {
                    "role": "user",
                    "content": prompt, 
                }
            ],
            model="gpt-3.5-turbo",
        )
        chatgpt_answer = completion.choices[0].message.content + " *answer generated by ChatGPT*"
        return chatgpt_answer

if __name__ == '__main__':
    app.run(debug=True)
