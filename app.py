from flask import Flask, render_template, request, jsonify
import os
from openai import OpenAI
from dotenv import load_dotenv
import time

# Initialize Flask app
app = Flask(__name__)

# Load environment variables
load_dotenv()

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
assistant_id = os.getenv("OPENAI_ASSISTANT_ID")

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    user_input = request.form['user_input']
    if user_input.lower() == 'exit':
        return jsonify({'response': 'Goodbye!'})
    else:
        answer = get_answer_from_chatbot(user_input)
        return jsonify({'response': answer})

def get_answer_from_chatbot(user_input):
    thread, run = create_thread_and_run(user_input)
    run = wait_on_run(run, thread)
    response = get_response(thread)
    # Assuming you only want the last response for simplicity
    chatgpt_answer = response.data[-1].content[0].text.value + " *answer generated by ChatGPT*"
    return chatgpt_answer

def create_thread_and_run(user_input):
    thread = client.beta.threads.create()
    run = submit_message(assistant_id, thread, user_input)
    return thread, run

def submit_message(assistant_id, thread, user_message):
    client.beta.threads.messages.create(
        thread_id=thread.id, role="user", content=user_message
    )
    return client.beta.threads.runs.create(
        thread_id=thread.id,
        assistant_id=assistant_id,
    )

def get_response(thread):
    return client.beta.threads.messages.list(thread_id=thread.id, order="asc")

def wait_on_run(run, thread):
    while run.status in ["queued", "in_progress"]:
        run = client.beta.threads.runs.retrieve(
            thread_id=thread.id,
            run_id=run.id,
        )
        time.sleep(0.5)
    return run

if __name__ == '__main__':
    app.run(debug=True)
